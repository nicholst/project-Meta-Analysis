{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import uniform, normal  \n",
    "import math\n",
    "from math import pi\n",
    "from scipy.optimize import Bounds\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J_square(sigma_square,tau_square):\n",
    "    return tau_square/(tau_square+sigma_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J square = [0.25, 0.3076923076923077, 0.5, 0.75]\n"
     ]
    }
   ],
   "source": [
    "# k: the number of studies\n",
    "k_list = [10,30,50,100]\n",
    "# each element of `parameter_constellation` has the form (mu, sigma^2,tau^2) \n",
    "# where tau^2 is the between-study variance, sigma^2*u_i is the within-study variance\n",
    "parameter_constellation = [(0,12,4),(0,9,4),(0,4,4),(0,2,6)]\n",
    "# heterogeniety measure: J^2\n",
    "J_square_list = list()\n",
    "for element in parameter_constellation:\n",
    "    sigma_square_i = element[1]\n",
    "    tau_square_i = element[2]\n",
    "    J_square_list.append(J_square(sigma_square_i,tau_square_i))\n",
    "print('J square =',J_square_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## method1: trying to minimize the negative log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the negative log likelihood function\n",
    "# minimize negative log likelihood function -> maximize log likelihood function\n",
    "def nll(x, D, u):\n",
    "    # x = np.array([mu, sigma, tau])\n",
    "    mu, sigma, tau = x[0], x[1], x[2]\n",
    "    sigma_square, tau_square = sigma**2, tau**2\n",
    "    return 1/2*np.sum((D - mu)**2/(tau_square + sigma_square*u) \\\n",
    "            +np.log(tau_square + sigma_square*u)+np.log(2*pi))\n",
    "\n",
    "# Jacobian: the matrix of all its first-order partial derivatives\n",
    "def jac(x, D, u):\n",
    "    mu, sigma, tau = x[0], x[1], x[2]\n",
    "    sigma_square, tau_square = sigma**2, tau**2\n",
    "    a = D - mu\n",
    "    b = tau_square + sigma_square * u\n",
    "    # convert the derivative with respect to sigma/tau, instead of sigma^2/tau^2\n",
    "    d_mu = np.sum(a / b)\n",
    "    d_sigma = (np.sum((a**2 * u) / b**2) - np.sum(u / b)) * (2*sigma) \n",
    "    d_tau = (np.sum(a**2 / b**2) - np.sum(1./ b)) * (2*tau)\n",
    "    return - np.array([d_mu, d_sigma, d_tau])\n",
    "\n",
    "def func(x, D, u):\n",
    "    return nll(x, D, u), jac(x, D, u)\n",
    "\n",
    "#############\n",
    "\n",
    "def simulation(k, mu,sigma,tau,num_replications=10000):\n",
    "    # store the results of convergent mu/sigma/tau for each replication\n",
    "    all_mu_ast, all_sigma_square_ast, all_tau_square_ast = [], [], []\n",
    "\n",
    "    for i in range(num_replications):\n",
    "        # generate k(the number of studies) D_i\n",
    "        u_array = uniform(0.02,0.2,k)\n",
    "        u_inv_array = 1 / u_array\n",
    "        # x_i ~ N(mu,tau^2)\n",
    "        x_array = normal(mu,tau,k)\n",
    "        # D_i ~ N(x_i, sigma^2*u_i)\n",
    "        D_array = normal(x_array,sigma*u_array**0.5,k)\n",
    "\n",
    "        # Note that we cannot use the starting values suggested in Sangnawakij's paper\n",
    "        # since given tau^2, sigma^2 and mu are calculated under the condition that the derivatives are zero\n",
    "        # which leads to a stationary point\n",
    "\n",
    "        # random but resonable initial point\n",
    "        mu_0 = uniform(-2.0, 2.0)\n",
    "        sigma_0 = uniform(0., 15.)\n",
    "        tau_0 = uniform(0., 8.)\n",
    "        x0 = np.array([mu_0, sigma_0, tau_0])\n",
    "        minimizer = minimize(nll, x0, args=(D_array, u_array), method=\"BFGS\", jac=jac, tol=1e-10)   \n",
    "        #minimizer_kwargs = {\"method\": \"BFGS\", \"args\": (D_array, u_array), \"jac\":True}\n",
    "        # corresponding mu/sigma/tau when the negative log likelihood function is minimized\n",
    "        mu_ast, sigma_ast, tau_ast = minimizer.x\n",
    "        sigma_square_ast = sigma_ast**2\n",
    "        tau_square_ast = tau_ast**2\n",
    "        # print(\"mu: {0}, sigma_square: {1}, tau_square: {2}\".format(mu_ast, sigma_square_ast, tau_square_ast))\n",
    "        all_mu_ast.append(mu_ast)\n",
    "        all_sigma_square_ast.append(sigma_square_ast)\n",
    "        all_tau_square_ast.append(tau_square_ast)\n",
    "\n",
    "    # convert the list to numpy array\n",
    "    all_mu_ast = np.array(all_mu_ast)\n",
    "    all_sigma_square_ast = np.array(all_sigma_square_ast)\n",
    "    all_tau_square_ast = np.array(all_tau_square_ast)\n",
    "    \n",
    "    # return the result for mu/sigma/tau in the form of: [bias, std]\n",
    "    mu_info = [np.mean(all_mu_ast), np.mean(all_mu_ast)-mu, np.std(all_mu_ast)]\n",
    "    sigma_square_info = [np.mean(all_sigma_square_ast),np.mean(all_sigma_square_ast)-sigma_square, np.std(all_sigma_square_ast)]\n",
    "    tau_square_info = [np.mean(all_tau_square_ast),np.mean(all_tau_square_ast)-tau_square, np.std(all_tau_square_ast)]\n",
    "    return mu_info, sigma_square_info, tau_square_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 34s, sys: 1.21 s, total: 9min 35s\n",
      "Wall time: 9min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#(mu, sigma^2,tau^2): (0,12,4),(0,9,4),(0,4,4),(0,2,6)\n",
    "mu_mean, mu_bias, mu_se = [],[],[]\n",
    "sigma_square_mean, sigma_square_bias, sigma_square_se = [],[],[]\n",
    "tau_square_mean, tau_square_bias, tau_square_se = [],[],[]\n",
    "\n",
    "for para_combination in parameter_constellation:\n",
    "    for k in k_list:\n",
    "        # get the parameters\n",
    "        mu = para_combination[0]\n",
    "        sigma_square = para_combination[1]\n",
    "        sigma = np.sqrt(sigma_square)\n",
    "        tau_square = para_combination[2]\n",
    "        tau = np.sqrt(tau_square)\n",
    "        # simulate\n",
    "        each_simulation = simulation(k, mu,sigma,tau,num_replications=10000)\n",
    "        # append the results to lists\n",
    "        mu_mean.append(each_simulation[0][0])\n",
    "        mu_bias.append(each_simulation[0][1])\n",
    "        mu_se.append(each_simulation[0][2])\n",
    "        \n",
    "        sigma_square_mean.append(each_simulation[1][0])\n",
    "        sigma_square_bias.append(each_simulation[1][1])\n",
    "        sigma_square_se.append(each_simulation[1][2]) \n",
    "        \n",
    "        tau_square_mean.append(each_simulation[2][0])\n",
    "        tau_square_bias.append(each_simulation[2][1])\n",
    "        tau_square_se.append(each_simulation[2][2])\n",
    "\n",
    "#print('mean of mu_hat:', mu_mean)\n",
    "#print('bias of mu_hat:', mu_bias)\n",
    "#print('standard error of mu_hat:', mu_se)\n",
    "#print('----------------------------------------------------------------')\n",
    "#print('mean of sigma_square_hat:', sigma_square_mean)\n",
    "#print('bias of sigma_square_hat:', sigma_square_bias)\n",
    "#print('standard error of sigma_square_hat:', sigma_square_se)\n",
    "#print('----------------------------------------------------------------')\n",
    "#print('mean of tau_square_hat:', tau_square_mean)\n",
    "#print('bias of tau_square_hat:', tau_square_bias)\n",
    "#print('standard error of tau_square_hat:', tau_square_se)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrrrr}\n",
      "\\toprule\n",
      " J\\_square &    k &  bias(mu) &  bias(sigma\\textasciicircum 2) &  bias(tau\\textasciicircum 2) &  standard\\_error(mu) &  standard\\_error(sigma\\textasciicircum 2) &  standard\\_error(tau\\textasciicircum 2) \\\\\n",
      "\\midrule\n",
      " 0.250000 &   10 &  0.007375 &       8.516906 &    -1.435006 &            0.767052 &                24.644566 &               5.834693 \\\\\n",
      " 0.250000 &   30 & -0.002435 &       5.767365 &    -0.814487 &            0.431672 &                19.331316 &               2.058517 \\\\\n",
      " 0.250000 &   50 &  0.000513 &       3.604686 &    -0.491619 &            0.332171 &                16.491241 &               1.788568 \\\\\n",
      " 0.250000 &  100 &  0.005041 &       1.818044 &    -0.253294 &            0.235613 &                12.573685 &               1.381885 \\\\\n",
      " 0.307692 &   10 &  0.003879 &       9.559981 &    -1.535135 &            0.722793 &                22.255735 &               2.860925 \\\\\n",
      " 0.307692 &   30 &  0.000297 &       6.341221 &    -0.820384 &            0.442774 &                20.329165 &               2.065225 \\\\\n",
      " 0.307692 &   50 & -0.002187 &       4.425942 &    -0.570607 &            0.319320 &                15.029784 &               1.664736 \\\\\n",
      " 0.307692 &  100 &  0.001109 &       2.296471 &    -0.275083 &            0.228342 &                11.513167 &               1.258610 \\\\\n",
      " 0.500000 &   10 &  0.000520 &      11.592586 &    -1.723658 &            0.695893 &                20.005866 &               2.224482 \\\\\n",
      " 0.500000 &   30 &  0.002884 &       8.052260 &    -0.879629 &            0.422651 &                15.379772 &              12.530243 \\\\\n",
      " 0.500000 &   50 & -0.003394 &       5.593686 &    -0.678226 &            0.304501 &                12.684495 &               1.445219 \\\\\n",
      " 0.500000 &  100 &  0.000759 &       3.427241 &    -0.401260 &            0.214182 &                 9.264521 &               1.080628 \\\\\n",
      " 0.750000 &   10 &  0.000265 &      18.595061 &    -2.683530 &            0.822571 &                27.144300 &               3.306853 \\\\\n",
      " 0.750000 &   30 & -0.006980 &      12.569559 &    -1.572272 &            0.471589 &                20.235591 &               2.459796 \\\\\n",
      " 0.750000 &   50 & -0.001834 &       9.640904 &    -0.975077 &            0.470133 &                45.376111 &              13.918018 \\\\\n",
      " 0.750000 &  100 &  0.002158 &       6.357629 &    -0.734396 &            0.256390 &                11.943409 &               1.449628 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pd.dataframe to latex table\n",
    "df = pd.DataFrame({'J_square': [i for i in J_square_list for _ in range(4)],\n",
    "                   'k': k_list*4,\n",
    "                   #'mean_mu': mu_mean,\n",
    "                   #'mean(sigma^2)': sigma_square_mean,\n",
    "                   #'mean(tau^2)': tau_square_mean,\n",
    "                   'bias(mu)': mu_bias,\n",
    "                   'bias(sigma^2)': sigma_square_bias,\n",
    "                   'bias(tau^2)': tau_square_bias,\n",
    "                   'standard_error(mu)': mu_se,\n",
    "                   'standard_error(sigma^2)': sigma_square_se,\n",
    "                   'standard_error(tau^2)': tau_square_se})\n",
    "print(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## method2: trying to calculate the maximum log likehood estimates of mu/sigma/tau iteratively (fixed point algorithm in Sangnawakij's paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### starting value\n",
    "$$\\tau_0^2 = 0$$\n",
    "$$\\hat{\\mu_0} = \\frac{\\sum \\limits_{i=1}^{k} \\frac{D_i}{u_i}}{\\sum \\limits_{i=1}^{k} \\frac{1}{u_i}}$$\n",
    "$$\\hat{\\sigma_0}^2 = \\frac{1}{k} \\sum \\limits_{i=1}^{k} \\frac{(D_i - \\hat{\\mu_0})^2}{u_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iterative steps\n",
    "$$\\mu_{s+1} = \\frac{\\sum \\limits_{i=1}^{k}\\frac{D_i}{\\tau_s^2+\\sigma_s^2 u_i}}{\\sum \\limits_{i=1}^{k} \\frac{1}{\\tau_s^2+\\sigma_s^2 u_i}}$$\n",
    "$$\\sigma_{s+1}^2 = \\frac{\\sum \\limits_{i=1}^{k} \\frac{(D_i - \\mu_s)^2 u_i - \\tau_s^2 u_i}{(\\tau_s^2 + \\sigma_s^2 u_i)^2}}{\\sum \\limits_{i=1}^{k}\\frac{u_i^2}{(\\tau_s^2+\\sigma_s^2 u_i)^2}} $$\n",
    "$$\\tau_{s+1}^2 = \\frac{\\sum \\limits_{i=1}^{k} \\frac{(D_i - \\mu_s)^2 - \\sigma_s^2 u_i}{(\\tau_s^2 + \\sigma_s^2 u_i)^2}}{\\sum \\limits_{i=1}^{k}\\frac{1}{(\\tau_s^2+\\sigma_s^2 u_i)^2}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_fp(k, actual_mu,actual_sigma,actual_tau,num_replications=10000,stopping_criteria = 1e-10):\n",
    "    actual_sigma_square = actual_sigma**2\n",
    "    actual_tau_square = actual_tau**2\n",
    "    \n",
    "    count_array = np.array([])\n",
    "    mu_array = np.array([])\n",
    "    tau_square_array = np.array([])\n",
    "    sigma_square_array = np.array([])\n",
    "\n",
    "    #for num in range(replications):\n",
    "    while len(count_array) < num_replications:\n",
    "        # firstly, generate all u_i and D_i from normal distribution\n",
    "        u_array = uniform(0.02,0.2,k)\n",
    "        # xi_i ~ N(mu,tau^2)\n",
    "        xi_array = normal(actual_mu,actual_tau,k)\n",
    "        # D_i ~ N(x_i, sigma^2*u_i)\n",
    "        D_array = normal(xi_array,actual_sigma*u_array**0.5,k)\n",
    "        u_inv_array = 1/u_array\n",
    "\n",
    "        # starting value\n",
    "        tau_square_hat_0 = 0\n",
    "        mu_hat_0 = np.sum(D_array*u_inv_array)/np.sum(u_inv_array)\n",
    "        sigma_square_hat_0 = 1/k*np.sum((D_array - mu_hat_0)**2/u_array) \n",
    "\n",
    "        log_likelihood = -1/2*np.sum((D_array - mu_hat_0)**2/(tau_square_hat_0 + sigma_square_hat_0*u_array)+np.log(tau_square_hat_0 + sigma_square_hat_0*u_array)+np.log(2*pi))\n",
    "        #print('The log likelihood corresponding to starting values is', log_likelihood)\n",
    "\n",
    "        mu = mu_hat_0\n",
    "        tau = np.sqrt(tau_square_hat_0)\n",
    "        sigma= np.sqrt(sigma_square_hat_0)\n",
    "\n",
    "\n",
    "\n",
    "        #########\n",
    "        count = 0\n",
    "        error = 1\n",
    "        while error > stopping_criteria:\n",
    "            tau_square = tau**2\n",
    "            sigma_square = sigma**2\n",
    "\n",
    "            # calculate the common terms firstly to avoid repeated calculation\n",
    "            common_term = 1/(tau_square + sigma_square*u_array)\n",
    "            common_term_square = common_term**2\n",
    "            D_minus_u_square = (D_array - mu)**2\n",
    "\n",
    "            # iterative equations\n",
    "            mu_updated = np.sum(D_array*common_term) / np.sum(common_term)\n",
    "            sigma_square_updated = np.sum((D_minus_u_square*u_array - tau_square*u_array)*common_term_square)/np.sum(u_array**2*common_term_square)\n",
    "            tau_square_updated = np.sum((D_minus_u_square - sigma_square*u_array)*common_term_square)/np.sum(common_term_square)\n",
    "            log_likelihood = -1/2*np.sum((D_array - mu_updated)**2/(tau_square_updated + sigma_square_updated*u_array)+np.log(tau_square_updated + sigma_square_updated*u_array)+np.log(2*pi))\n",
    "\n",
    "\n",
    "            # use sigma/tau -> unconstrained problem\n",
    "            sigma_updated = np.sqrt(sigma_square_updated)\n",
    "            tau_updated = np.sqrt(tau_square_updated)\n",
    "\n",
    "            #print('log likelihood:',log_likelihood)\n",
    "\n",
    "            #print(abs(mu_updated-mu))\n",
    "            #print(abs(sigma_updated-sigma))\n",
    "            #print(abs(tau_updated-tau))\n",
    "            #print('----------------------------------')\n",
    "\n",
    "            error = max(abs(mu_updated-mu),abs(sigma_updated-sigma),abs(tau_updated-tau))\n",
    "            #print('max error = ',error)\n",
    "\n",
    "            mu = mu_updated\n",
    "            sigma = sigma_updated\n",
    "            tau = tau_updated\n",
    "            count += 1\n",
    "\n",
    "        # only keep the cases which is convergent and sigma_square/tau_square are non-negative\n",
    "        if (count>1) and (math.isnan(mu) == False) and (math.isnan(sigma) == False) and (math.isnan(tau) == False):\n",
    "            count_array = np.append(count_array, count)\n",
    "            mu_array = np.append(mu_array, mu)\n",
    "            sigma_square_array = np.append(sigma_square_array,sigma_square)\n",
    "            tau_square_array = np.append(tau_square_array, tau_square)\n",
    "            \n",
    "            \n",
    "    mu_info = [np.mean(mu_array), np.mean(mu_array)-actual_mu, np.std(mu_array)]\n",
    "    sigma_square_info = [np.mean(sigma_square_array),np.mean(sigma_square_array)-actual_sigma_square, np.std(sigma_square_array)]\n",
    "    tau_square_info = [np.mean(tau_square_array),np.mean(tau_square_array)-actual_tau_square, np.std(tau_square_array)]\n",
    "    return mu_info, sigma_square_info, tau_square_info\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in sqrt\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:54: RuntimeWarning: invalid value encountered in sqrt\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:50: RuntimeWarning: invalid value encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47min 34s, sys: 5.41 s, total: 47min 40s\n",
      "Wall time: 47min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#(mu, sigma^2,tau^2): (0,12,4),(0,9,4),(0,4,4),(0,2,6)\n",
    "mu_mean_fp, mu_bias_fp, mu_se_fp = [],[],[]\n",
    "sigma_square_mean_fp, sigma_square_bias_fp, sigma_square_se_fp = [],[],[]\n",
    "tau_square_mean_fp, tau_square_bias_fp, tau_square_se_fp = [],[],[]\n",
    "\n",
    "for para_combination in parameter_constellation:\n",
    "    for k in k_list:\n",
    "        # get the parameters\n",
    "        actual_mu = para_combination[0]\n",
    "        actual_sigma_square = para_combination[1]\n",
    "        actual_sigma = np.sqrt(actual_sigma_square)\n",
    "        actual_tau_square = para_combination[2]\n",
    "        actual_tau = np.sqrt(actual_tau_square)\n",
    "        # simulate\n",
    "        each_simulation_fp = simulation_fp(k, actual_mu,actual_sigma,actual_tau,num_replications=10000,stopping_criteria = 1e-10)\n",
    "        # append the results to lists\n",
    "        mu_mean_fp.append(each_simulation_fp[0][0])\n",
    "        mu_bias_fp.append(each_simulation_fp[0][1])\n",
    "        mu_se_fp.append(each_simulation_fp[0][2])\n",
    "        \n",
    "        sigma_square_mean_fp.append(each_simulation_fp[1][0])\n",
    "        sigma_square_bias_fp.append(each_simulation_fp[1][1])\n",
    "        sigma_square_se_fp.append(each_simulation_fp[1][2]) \n",
    "        \n",
    "        tau_square_mean_fp.append(each_simulation_fp[2][0])\n",
    "        tau_square_bias_fp.append(each_simulation_fp[2][1])\n",
    "        tau_square_se_fp.append(each_simulation_fp[2][2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrrrr}\n",
      "\\toprule\n",
      " J\\_square &    k &  bias(mu) &  bias(sigma\\textasciicircum 2) &  bias(tau\\textasciicircum 2) &  standard\\_error(mu) &  standard\\_error(sigma\\textasciicircum 2) &  standard\\_error(tau\\textasciicircum 2) \\\\\n",
      "\\midrule\n",
      " 0.250000 &   10 & -0.001991 &      11.291183 &    -1.656066 &            0.733642 &                18.556028 &               1.826939 \\\\\n",
      " 0.250000 &   30 &  0.000815 &      10.635056 &    -1.265305 &            0.427278 &                14.990208 &               1.577687 \\\\\n",
      " 0.250000 &   50 & -0.002636 &       8.665148 &    -1.002207 &            0.330845 &                13.728933 &               1.482482 \\\\\n",
      " 0.250000 &  100 & -0.001472 &       5.402168 &    -0.633542 &            0.231044 &                11.059670 &               1.223603 \\\\\n",
      " 0.307692 &   10 & -0.012355 &      12.725499 &    -1.755441 &            0.715221 &                17.255368 &               1.738297 \\\\\n",
      " 0.307692 &   30 &  0.001083 &      11.742043 &    -1.375706 &            0.416264 &                13.981466 &               1.506994 \\\\\n",
      " 0.307692 &   50 &  0.000241 &       9.614026 &    -1.111411 &            0.323687 &                12.621144 &               1.391023 \\\\\n",
      " 0.307692 &  100 &  0.002041 &       5.892569 &    -0.672846 &            0.224135 &                10.133364 &               1.134173 \\\\\n",
      " 0.500000 &   10 & -0.001918 &      14.663140 &    -1.973830 &            0.687635 &                14.968066 &               1.545956 \\\\\n",
      " 0.500000 &   30 &  0.003999 &      13.639589 &    -1.586143 &            0.394349 &                12.241310 &               1.345811 \\\\\n",
      " 0.500000 &   50 &  0.000109 &      11.415912 &    -1.312918 &            0.304104 &                10.947534 &               1.222297 \\\\\n",
      " 0.500000 &  100 &  0.002551 &       7.789837 &    -0.890689 &            0.212897 &                 8.403318 &               0.974565 \\\\\n",
      " 0.750000 &   10 &  0.004901 &      24.107686 &    -3.184620 &            0.814910 &                20.874419 &               2.175859 \\\\\n",
      " 0.750000 &   30 &  0.000257 &      21.243568 &    -2.488732 &            0.468724 &                16.782663 &               1.911737 \\\\\n",
      " 0.750000 &   50 & -0.001907 &      18.186248 &    -2.100759 &            0.360339 &                14.727956 &               1.715353 \\\\\n",
      " 0.750000 &  100 &  0.002298 &      12.761487 &    -1.452832 &            0.251640 &                11.113719 &               1.357419 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print('mean of mu_hat:', mu_mean_fp)\n",
    "#print('bias of mu_hat:', mu_bias_fp)\n",
    "#print('standard error of mu_hat:', mu_se_fp)\n",
    "#print('----------------------------------------------------------------')\n",
    "#print('mean of sigma_square_hat:', sigma_square_mean_fp)\n",
    "#print('bias of sigma_square_hat:', sigma_square_bias_fp)\n",
    "#print('standard error of sigma_square_hat:', sigma_square_se_fp)\n",
    "#print('----------------------------------------------------------------')\n",
    "#print('mean of tau_square_hat:', tau_square_mean_fp)\n",
    "#print('bias of tau_square_hat:', tau_square_bias_fp)\n",
    "#print('standard error of tau_square_hat:', tau_square_se_fp)\n",
    "\n",
    "# from pd.dataframe to latex table\n",
    "df_fp = pd.DataFrame({'J_square': [i for i in J_square_list for _ in range(4)],\n",
    "                   'k': k_list*4,\n",
    "                   #'mean_mu': mu_mean,\n",
    "                   #'mean(sigma^2)': sigma_square_mean,\n",
    "                   #'mean(tau^2)': tau_square_mean,\n",
    "                   'bias(mu)': mu_bias_fp,\n",
    "                   'bias(sigma^2)': sigma_square_bias_fp,\n",
    "                   'bias(tau^2)': tau_square_bias_fp,\n",
    "                   'standard_error(mu)': mu_se_fp,\n",
    "                   'standard_error(sigma^2)': sigma_square_se_fp,\n",
    "                   'standard_error(tau^2)': tau_square_se_fp})\n",
    "print(df_fp.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is method 1\n",
    "\n",
    "If we let $c=\\sqrt{a+b}$ then we'll find truth, but\n",
    "$$\n",
    "F(x) = \\int_{-\\infty}^x f(t) dt\n",
    "$$\n",
    "then we really know what's up, or\n",
    "\\begin{eqnarray}\n",
    "a&=&b\\\\\n",
    "&=&c\n",
    "\\end{eqnarray}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
